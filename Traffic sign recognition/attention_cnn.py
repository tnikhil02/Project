# -*- coding: utf-8 -*-
"""ATTENTION-CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BF_bn-LpTUTrV4_UFa-q_BAcBOlNz4Qj
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import pathlib
import glob
import os

from tensorflow.keras.layers import Dense , Flatten , Dropout , Conv2D , MaxPooling2D , Layer,Rescaling
from tensorflow.keras.models import Model , Sequential
#from tensorflow.keras.layers.preprocessing import Rescaling

#mounting google deic
from google.colab import drive
drive.mount('/content/gdrive')

#loading labels
path = '/content/gdrive/MyDrive/dataset-1/DATASET-1/labels.csv'
df = pd.read_csv(path)
dataset = '/content/gdrive/MyDrive/dataset-1/DATASET-1/traffic_Data/DATA'

df

# @title ClassId

from matplotlib import pyplot as plt
df['ClassId'].plot(kind='line', figsize=(8, 4), title='ClassId')
plt.gca().spines[['top', 'right']].set_visible(False)







# Preparing Data for Visualization
data = []
entry = []
for filename in os.listdir(dataset):
  entry.append(df['Name'][int(filename)])
  entry.append(int(filename))
  data.append(entry[:2])
  entry.clear()

# Creating Dataframe for Visualization
display_data = pd.DataFrame(data,columns=['Name' , 'num_images'])

# Plotting Number of Images per Class
plt.figure(figsize=(15,25))
ax = sns.barplot(x='num_images',y='Name' , data=display_data)
plt.show()

!pip install imbalanced-learn

# Loading and Splitting Dataset
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
                                                  '/content/gdrive/MyDrive/dataset-1/DATASET-1/traffic_Data/DATA'
                                                  ,validation_split=0.2,
                                                    subset='training',
                                                    image_size=(224,224),
                                                    seed=123,
                                                    batch_size=32)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
                                                   '/content/gdrive/MyDrive/dataset-1/DATASET-1/traffic_Data/DATA' ,
                                                    validation_split=0.2,
                                                    subset='validation',
                                                    image_size=(224,224),
                                                    seed=123,
                                                    batch_size=32)

# Creating Class Names for Visualization
class_numbers = train_ds.class_names
class_names = []
for i in class_numbers:
 class_names.append(df['Name'][int(i)])

# Visualizing Training Images
plt.figure(figsize=(25, 25))
for images, labels in train_ds.take(1):
  for i in range(20):
    ax = plt.subplot(10, 10, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

plt.show()

data_augmentation = tf.keras.Sequential([
    tf.keras.layers.RandomFlip("horizontal", input_shape=(224, 224, 3)),
    tf.keras.layers.RandomRotation(0.1),
    tf.keras.layers.RandomZoom(0.2),
    tf.keras.layers.RandomFlip(mode="horizontal_and_vertical")
])

# Define Spatial Attention Module
class SpatialAttention(Layer):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()
        self.conv = Conv2D(1, kernel_size, padding='same', activation='sigmoid')

    def call(self, inputs):
        avg_out = tf.reduce_mean(inputs, axis=3, keepdims=True)
        max_out = tf.reduce_max(inputs, axis=3, keepdims=True)
        concat = tf.concat([avg_out, max_out], axis=3)
        return inputs * self.conv(concat)

model = Sequential()
# Define model
model.add(Rescaling(1./255, input_shape=(224, 224, 3)))
model.add(data_augmentation)
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(SpatialAttention())
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(SpatialAttention())
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(SpatialAttention())
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(SpatialAttention())
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(SpatialAttention())
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(256, (3, 3), activation='relu'))
model.add(SpatialAttention())
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())
model.add(Dense(64 , activation = 'relu'))
model.add(Dropout(0.2))
model.add(Dense(128 , activation = 'relu'))
model.add(Dense(len(df) , activation = 'softmax'))
model.summary()

model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer='adam' , metrics=['accuracy'])

# Training the Model
hist = model.fit(train_ds,validation_data=val_ds, epochs=30 )

import matplotlib.pyplot as plt

plt.plot(hist.history['accuracy'],color='red',label='train')
plt.plot(hist.history['val_accuracy'],color='blue',label='validation')

plt.plot(hist.history['loss'],color='red',label='train')
plt.plot(hist.history['val_loss'],color='blue',label='validation')

loss, accuracy = model.evaluate(val_ds)
print(f'Validation loss: {loss}')
print(f'Validation accuracy: {accuracy}')

# Define the path to save the model
model_save_path = '/content/gdrive/MyDrive/intern-project/CNNmodel.keras'

# Save the model
model.save(model_save_path)

import pandas as pd
from tensorflow.keras.preprocessing import image
import numpy as np

def load_and_preprocess_image(img_path):
  """Loads an image from a file, converts it to RGB, resizes it, and normalizes it."""
  img = image.load_img(img_path, target_size=(224, 224))  # Load image and resize
  img = image.img_to_array(img)  # Convert to array
  img = img.astype('float32') / 255.0  # Normalize pixel values
  img = np.expand_dims(img, axis=0)  # Add batch dimension
  return img

test_img_path = '/content/gdrive/MyDrive/dataset-1/DATASET-1/traffic_Data/TEST/015_1_0004_1_j.png'
test_img_array = load_and_preprocess_image(test_img_path)

# Make predictions
predictions = model.predict(test_img_array)


# Create a dictionary mapping class IDs to names
class_labels = dict(zip(df['ClassId'], df['Name']))

predicted_class_index = np.argmax(predictions)
predicted_class_label = class_labels.get(predicted_class_index)

print(f"Predicted class index: {predicted_class_index}")
print(f"Predicted class label: {predicted_class_label}")